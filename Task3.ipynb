{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "Task3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "niwpNf_EYNC9",
        "TvhXRmGyYNC_",
        "ZBLwVsQIYNDA",
        "a7pxLfloYNDM",
        "QPOM6rXpYNDW",
        "LDYWYnvwYNDY",
        "OIFaYgUWYNDa",
        "vWiXgySxYNDd",
        "N6tS1j4iYNDe"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prathambhoir55/Synapse-Learning-period/blob/week3/Task3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GKIJx3sYNC0"
      },
      "source": [
        "# Task 2\n",
        "This week you have learnt about various types of ML models. <br>\n",
        "Let us focus on two of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ4lXvV6YW_5",
        "outputId": "0c1956fd-45c4-44f9-f3dd-b6724ab39488"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 1019,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKEbTpqVYg8m"
      },
      "source": [
        "# Instructions\n",
        "1. create a folder called synapse_w2 in your drive\n",
        "2. add housing_data.csv, classified_data.txt, titanic_data.csv in the folder.\n",
        "3. You will use the data from this path in this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88aLM-5hYgVL"
      },
      "source": [
        ""
      ],
      "execution_count": 1019,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJqOW8lFYNC3"
      },
      "source": [
        "# 1)  Linear Regression on Housing Price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZGyek2wYNC4"
      },
      "source": [
        "### Import packages and dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C--rF9aZYNC4"
      },
      "source": [
        "# import numpy, pandas, matplotlib, seaborn\n",
        "# add code here\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "execution_count": 1020,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8Kgu-VJYNC5"
      },
      "source": [
        "**Read housing_data.csv using pandas and call head() to show first few records.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrdEbQKxYNC5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "9311fbac-6a42-4b5e-ac01-9bfc235abcd4"
      },
      "source": [
        "# add code here\n",
        "housing_data_path = \"/content/gdrive/My Drive/synapse_w2/housing_data.csv\"\n",
        "\n",
        "df = pd.read_csv(housing_data_path)\n",
        "df.head()"
      ],
      "execution_count": 1021,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Avg. Area Income</th>\n",
              "      <th>Avg. Area House Age</th>\n",
              "      <th>Avg. Area Number of Rooms</th>\n",
              "      <th>Avg. Area Number of Bedrooms</th>\n",
              "      <th>Area Population</th>\n",
              "      <th>Price</th>\n",
              "      <th>Address</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>79545.458574</td>\n",
              "      <td>5.682861</td>\n",
              "      <td>7.009188</td>\n",
              "      <td>4.09</td>\n",
              "      <td>23086.800503</td>\n",
              "      <td>1.059034e+06</td>\n",
              "      <td>208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>79248.642455</td>\n",
              "      <td>6.002900</td>\n",
              "      <td>6.730821</td>\n",
              "      <td>3.09</td>\n",
              "      <td>40173.072174</td>\n",
              "      <td>1.505891e+06</td>\n",
              "      <td>188 Johnson Views Suite 079\\nLake Kathleen, CA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61287.067179</td>\n",
              "      <td>5.865890</td>\n",
              "      <td>8.512727</td>\n",
              "      <td>5.13</td>\n",
              "      <td>36882.159400</td>\n",
              "      <td>1.058988e+06</td>\n",
              "      <td>9127 Elizabeth Stravenue\\nDanieltown, WI 06482...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63345.240046</td>\n",
              "      <td>7.188236</td>\n",
              "      <td>5.586729</td>\n",
              "      <td>3.26</td>\n",
              "      <td>34310.242831</td>\n",
              "      <td>1.260617e+06</td>\n",
              "      <td>USS Barnett\\nFPO AP 44820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59982.197226</td>\n",
              "      <td>5.040555</td>\n",
              "      <td>7.839388</td>\n",
              "      <td>4.23</td>\n",
              "      <td>26354.109472</td>\n",
              "      <td>6.309435e+05</td>\n",
              "      <td>USNS Raymond\\nFPO AE 09386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Avg. Area Income  ...                                            Address\n",
              "0      79545.458574  ...  208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...\n",
              "1      79248.642455  ...  188 Johnson Views Suite 079\\nLake Kathleen, CA...\n",
              "2      61287.067179  ...  9127 Elizabeth Stravenue\\nDanieltown, WI 06482...\n",
              "3      63345.240046  ...                          USS Barnett\\nFPO AP 44820\n",
              "4      59982.197226  ...                         USNS Raymond\\nFPO AE 09386\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1021
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_158HqRTYNC6"
      },
      "source": [
        "### Exloratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbmnOZ48YNC6"
      },
      "source": [
        "**'info()' method to check the data types and number**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YWr6trZYNC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7705b68f-371b-4396-96c6-fc0a138a1a35"
      },
      "source": [
        "# add code here\n",
        "df.info()\n"
      ],
      "execution_count": 1022,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 7 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   Avg. Area Income              5000 non-null   float64\n",
            " 1   Avg. Area House Age           5000 non-null   float64\n",
            " 2   Avg. Area Number of Rooms     5000 non-null   float64\n",
            " 3   Avg. Area Number of Bedrooms  5000 non-null   float64\n",
            " 4   Area Population               5000 non-null   float64\n",
            " 5   Price                         5000 non-null   float64\n",
            " 6   Address                       5000 non-null   object \n",
            "dtypes: float64(6), object(1)\n",
            "memory usage: 273.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XVB-HteYNC7"
      },
      "source": [
        "**Get the statistical summary of the data set** <br>\n",
        "Hint: describe()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZPbIjgYYNC7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "3a9a7009-b8e0-4668-b654-8a88b8a2f74a"
      },
      "source": [
        "# add code here\n",
        "df.describe()"
      ],
      "execution_count": 1023,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Avg. Area Income</th>\n",
              "      <th>Avg. Area House Age</th>\n",
              "      <th>Avg. Area Number of Rooms</th>\n",
              "      <th>Avg. Area Number of Bedrooms</th>\n",
              "      <th>Area Population</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>5.000000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>68583.108984</td>\n",
              "      <td>5.977222</td>\n",
              "      <td>6.987792</td>\n",
              "      <td>3.981330</td>\n",
              "      <td>36163.516039</td>\n",
              "      <td>1.232073e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>10657.991214</td>\n",
              "      <td>0.991456</td>\n",
              "      <td>1.005833</td>\n",
              "      <td>1.234137</td>\n",
              "      <td>9925.650114</td>\n",
              "      <td>3.531176e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>17796.631190</td>\n",
              "      <td>2.644304</td>\n",
              "      <td>3.236194</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>172.610686</td>\n",
              "      <td>1.593866e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>61480.562388</td>\n",
              "      <td>5.322283</td>\n",
              "      <td>6.299250</td>\n",
              "      <td>3.140000</td>\n",
              "      <td>29403.928702</td>\n",
              "      <td>9.975771e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>68804.286404</td>\n",
              "      <td>5.970429</td>\n",
              "      <td>7.002902</td>\n",
              "      <td>4.050000</td>\n",
              "      <td>36199.406689</td>\n",
              "      <td>1.232669e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>75783.338666</td>\n",
              "      <td>6.650808</td>\n",
              "      <td>7.665871</td>\n",
              "      <td>4.490000</td>\n",
              "      <td>42861.290769</td>\n",
              "      <td>1.471210e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>107701.748378</td>\n",
              "      <td>9.519088</td>\n",
              "      <td>10.759588</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>69621.713378</td>\n",
              "      <td>2.469066e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Avg. Area Income  Avg. Area House Age  ...  Area Population         Price\n",
              "count       5000.000000          5000.000000  ...      5000.000000  5.000000e+03\n",
              "mean       68583.108984             5.977222  ...     36163.516039  1.232073e+06\n",
              "std        10657.991214             0.991456  ...      9925.650114  3.531176e+05\n",
              "min        17796.631190             2.644304  ...       172.610686  1.593866e+04\n",
              "25%        61480.562388             5.322283  ...     29403.928702  9.975771e+05\n",
              "50%        68804.286404             5.970429  ...     36199.406689  1.232669e+06\n",
              "75%        75783.338666             6.650808  ...     42861.290769  1.471210e+06\n",
              "max       107701.748378             9.519088  ...     69621.713378  2.469066e+06\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1023
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfSgsewYYNC7"
      },
      "source": [
        "**Print the names of the columns(features)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ss5VF20YNC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "731a40db-9568-44a2-8a14-37cc1a6ccc33"
      },
      "source": [
        "# add code here\n",
        "\n",
        "for column in df.columns:\n",
        "  print(column)"
      ],
      "execution_count": 1024,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg. Area Income\n",
            "Avg. Area House Age\n",
            "Avg. Area Number of Rooms\n",
            "Avg. Area Number of Bedrooms\n",
            "Area Population\n",
            "Price\n",
            "Address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0HiN5NeYNC8"
      },
      "source": [
        "### Basic plotting and visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rumpxTXYNC8"
      },
      "source": [
        "**The target quantity is price. Let us see its distribution.** <br>\n",
        "Plot a histogram of Price. Choose the number of bins by experimenting a little. (Expected: a bell curve shape)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BGkFMVBYNC8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "0c7b1b2e-421a-4036-84a1-0f3851d39ca8"
      },
      "source": [
        "# add code here\n",
        "\n",
        "x = df['Price']\n",
        "plt.xlabel(\"Price\")\n",
        "plt.hist(x, bins= 30)\n",
        "plt.show()"
      ],
      "execution_count": 1025,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al174yCyYNC9"
      },
      "source": [
        "**Let us see how the different features are correlated with each other by printing a Correlation Matrix**<br>\n",
        "Hint: corr()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "aaLwISKZYNC9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "aacb16ec-18f4-4153-bb4b-eec15380d931"
      },
      "source": [
        "# add code here\n",
        "\n",
        "df.corr()"
      ],
      "execution_count": 1026,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Avg. Area Income</th>\n",
              "      <th>Avg. Area House Age</th>\n",
              "      <th>Avg. Area Number of Rooms</th>\n",
              "      <th>Avg. Area Number of Bedrooms</th>\n",
              "      <th>Area Population</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Avg. Area Income</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.002007</td>\n",
              "      <td>-0.011032</td>\n",
              "      <td>0.019788</td>\n",
              "      <td>-0.016234</td>\n",
              "      <td>0.639734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Avg. Area House Age</th>\n",
              "      <td>-0.002007</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.009428</td>\n",
              "      <td>0.006149</td>\n",
              "      <td>-0.018743</td>\n",
              "      <td>0.452543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Avg. Area Number of Rooms</th>\n",
              "      <td>-0.011032</td>\n",
              "      <td>-0.009428</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.462695</td>\n",
              "      <td>0.002040</td>\n",
              "      <td>0.335664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Avg. Area Number of Bedrooms</th>\n",
              "      <td>0.019788</td>\n",
              "      <td>0.006149</td>\n",
              "      <td>0.462695</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.022168</td>\n",
              "      <td>0.171071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Area Population</th>\n",
              "      <td>-0.016234</td>\n",
              "      <td>-0.018743</td>\n",
              "      <td>0.002040</td>\n",
              "      <td>-0.022168</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.408556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Price</th>\n",
              "      <td>0.639734</td>\n",
              "      <td>0.452543</td>\n",
              "      <td>0.335664</td>\n",
              "      <td>0.171071</td>\n",
              "      <td>0.408556</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              Avg. Area Income  ...     Price\n",
              "Avg. Area Income                      1.000000  ...  0.639734\n",
              "Avg. Area House Age                  -0.002007  ...  0.452543\n",
              "Avg. Area Number of Rooms            -0.011032  ...  0.335664\n",
              "Avg. Area Number of Bedrooms          0.019788  ...  0.171071\n",
              "Area Population                      -0.016234  ...  0.408556\n",
              "Price                                 0.639734  ...  1.000000\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1026
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niwpNf_EYNC9"
      },
      "source": [
        "### Feature and variable sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZRq4NakYNC9"
      },
      "source": [
        "**Make a list of data frame column names**\n",
        "**Create a new dataframe containing all the numerical training features(note that Address is a string so ignore that) and store it in a variable called \"X\"**<br><br>\n",
        "**Then create a new dataframe containing the target (Price) and store it in a variable called \"y\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBKubTuLYNC-"
      },
      "source": [
        "# add code here\n",
        "columns = list(df.columns)\n",
        "X = df.drop(columns=['Address', 'Price'])\n",
        "y = df[['Price']]"
      ],
      "execution_count": 1027,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w-pU7UhYNC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c257641c-2acf-427f-dc8b-793e4414115a"
      },
      "source": [
        "# This code should print (5000, 5) and (5000,) if everything is correct\n",
        "print(X.shape)\n",
        "y.shape"
      ],
      "execution_count": 1028,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 1028
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Enk28n7JEwRe",
        "outputId": "5ff57a6b-644b-41ae-99fd-5d8d135ec61d"
      },
      "source": [
        "y"
      ],
      "execution_count": 1029,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.059034e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.505891e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.058988e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.260617e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.309435e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>1.060194e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>1.482618e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>1.030730e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>1.198657e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>1.298950e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Price\n",
              "0     1.059034e+06\n",
              "1     1.505891e+06\n",
              "2     1.058988e+06\n",
              "3     1.260617e+06\n",
              "4     6.309435e+05\n",
              "...            ...\n",
              "4995  1.060194e+06\n",
              "4996  1.482618e+06\n",
              "4997  1.030730e+06\n",
              "4998  1.198657e+06\n",
              "4999  1.298950e+06\n",
              "\n",
              "[5000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1029
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC6JzmuDYNC-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1239af68-3642-4078-9921-1c600a0738de"
      },
      "source": [
        "# print a few record of X\n",
        "# add code here\n",
        "X.head()"
      ],
      "execution_count": 1030,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Avg. Area Income</th>\n",
              "      <th>Avg. Area House Age</th>\n",
              "      <th>Avg. Area Number of Rooms</th>\n",
              "      <th>Avg. Area Number of Bedrooms</th>\n",
              "      <th>Area Population</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>79545.458574</td>\n",
              "      <td>5.682861</td>\n",
              "      <td>7.009188</td>\n",
              "      <td>4.09</td>\n",
              "      <td>23086.800503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>79248.642455</td>\n",
              "      <td>6.002900</td>\n",
              "      <td>6.730821</td>\n",
              "      <td>3.09</td>\n",
              "      <td>40173.072174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61287.067179</td>\n",
              "      <td>5.865890</td>\n",
              "      <td>8.512727</td>\n",
              "      <td>5.13</td>\n",
              "      <td>36882.159400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63345.240046</td>\n",
              "      <td>7.188236</td>\n",
              "      <td>5.586729</td>\n",
              "      <td>3.26</td>\n",
              "      <td>34310.242831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59982.197226</td>\n",
              "      <td>5.040555</td>\n",
              "      <td>7.839388</td>\n",
              "      <td>4.23</td>\n",
              "      <td>26354.109472</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Avg. Area Income  ...  Area Population\n",
              "0      79545.458574  ...     23086.800503\n",
              "1      79248.642455  ...     40173.072174\n",
              "2      61287.067179  ...     36882.159400\n",
              "3      63345.240046  ...     34310.242831\n",
              "4      59982.197226  ...     26354.109472\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1030
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ9RkZ1-YNC-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ece31c16-526d-494f-c145-f12d7996bc89"
      },
      "source": [
        "# print a few record of y\n",
        "# add code here\n",
        "y.head()"
      ],
      "execution_count": 1031,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.059034e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.505891e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.058988e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.260617e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.309435e+05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Price\n",
              "0  1.059034e+06\n",
              "1  1.505891e+06\n",
              "2  1.058988e+06\n",
              "3  1.260617e+06\n",
              "4  6.309435e+05"
            ]
          },
          "metadata": {},
          "execution_count": 1031
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvhXRmGyYNC_"
      },
      "source": [
        "### Test-train split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-I6E4XuYNC_"
      },
      "source": [
        "**Import train_test_split function from scikit-learn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ2t9WC4YNC_"
      },
      "source": [
        "# add code here\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1032,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTHAGB7pYNC_"
      },
      "source": [
        "**Create X and y train and test splits in one command using a test size of 0.3 and a random seed**<br>\n",
        "They should be called X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZWMHfPcYNC_"
      },
      "source": [
        "# add code here\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=55)"
      ],
      "execution_count": 1033,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyfldBi7YNDA"
      },
      "source": [
        "**Print the size and shape of each of the train/test splits (it should be in the ratio as per test_size parameter above)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTMhv-xlYNDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e88c492-067e-41d1-b744-7af12683644a"
      },
      "source": [
        "# add code here\n",
        "print('X_train\\nSize=',X_train.size,' Shape=',X_train.shape)\n",
        "print('\\nX_test\\nSize=',X_test.size,' Shape=',X_test.shape)\n",
        "print('\\ny_train\\nSize=',y_train.size,' Shape=',y_train.shape)\n",
        "print('\\ny_test\\nSize=',y_test.size,' Shape=',y_test.shape)\n"
      ],
      "execution_count": 1034,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train\n",
            "Size= 17500  Shape= (3500, 5)\n",
            "\n",
            "X_test\n",
            "Size= 7500  Shape= (1500, 5)\n",
            "\n",
            "y_train\n",
            "Size= 3500  Shape= (3500, 1)\n",
            "\n",
            "y_test\n",
            "Size= 1500  Shape= (1500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBLwVsQIYNDA"
      },
      "source": [
        "### Model fit and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNPr5Xb0YNDA"
      },
      "source": [
        "**Import LinearRegression and metrics from scikit-learn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llBzX5-EYNDA"
      },
      "source": [
        "# add code for imports here\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create a Linear Regression object 'lm' by calling LinearRegression()\n",
        "# add code here\n",
        "\n",
        "lm = LinearRegression()"
      ],
      "execution_count": 1035,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRzoOJXhYNDA"
      },
      "source": [
        "**Fit the model on to the instantiated object itself using the X_train and y_train created earlier. No need to create another variable**<br>\n",
        "Hint: lm.fit()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9U1pME1YNDB"
      },
      "source": [
        "# add code here\n",
        "#lm.fit(X_train, y_train)"
      ],
      "execution_count": 1036,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl54AGXT7v2m"
      },
      "source": [
        "**K-Fold**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViobBwla7z40"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import r2_score\n",
        "from statistics import mean\n",
        "\n",
        "\n",
        "scores= []\n",
        "kf = KFold(n_splits=9)\n",
        "for train_index, test_index in kf.split(X_train):\n",
        "  X_train_kf, X_test_kf = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "  y_train_kf, y_test_kf = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "  lm.fit(X_train_kf, y_train_kf)\n",
        "  pred = lm.predict(X_test_kf)\n",
        "  scores.append(round(r2_score(pred, y_test_kf), 3))\n"
      ],
      "execution_count": 1037,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7pxLfloYNDM"
      },
      "source": [
        "### Prediction, error estimate, and regression evaluation matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOXcTK_iYNDN"
      },
      "source": [
        "**Prediction using the lm model**<br>\n",
        "Use model.predict() on X_test and store them in a variable called \"predictions\".<br>\n",
        "Print type and size of the predictions. Size should be (1500,) if everything is correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef28Cy7pYNDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76736075-3698-486f-c750-28e3f1dad6ad"
      },
      "source": [
        "# add code here\n",
        "predictions = lm.predict(X_test)\n",
        "print('Type =', type(predictions), 'Size= ', predictions.size)"
      ],
      "execution_count": 1038,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type = <class 'numpy.ndarray'> Size=  1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPM6_2M5YNDQ"
      },
      "source": [
        "**Since we're done with our predictions, let's compare it with y_test and see how accurate our predictions are.<br> Plot a Scatter plot of predicted price and y_test set to see if the data fall on a 45 degree straight line**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "2T7YcpWMYNDQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "30d2591b-4883-4565-e444-fd1029d4b1a5"
      },
      "source": [
        "# add code here\n",
        "plt.figure(figsize= (20,10))\n",
        "plt.xlabel(\"predictions\")\n",
        "plt.ylabel(\"y_test\")\n",
        "plt.scatter(predictions, y_test)\n",
        "plt.show()"
      ],
      "execution_count": 1039,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZtFB738YNDS"
      },
      "source": [
        "**Print the R-square value and round it to 3 decimal places**<br>\n",
        "Hint: sklearn metrics.r2_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGKgAkCDYNDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdce576-af04-45fb-bbce-755ab3463ce0"
      },
      "source": [
        "# add code here\n",
        "print('Test accuracy=', round(r2_score(predictions, y_test), 3))\n",
        "print('Train accuracy=', round(mean(scores), 3))\n"
      ],
      "execution_count": 1040,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy= 0.916\n",
            "Train accuracy= 0.909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jroGWezYNDT"
      },
      "source": [
        "# 2) K-nearest neighbor Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHlWn6YXYNDU"
      },
      "source": [
        "### Import packages and dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJAjpGbYYNDU"
      },
      "source": [
        "# import numpy, pandas, matplotlib, seaborn\n",
        "# add code here\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1041,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RWyQOGrYNDV"
      },
      "source": [
        "**Read classified_data.txt using pandas and call head() to show first few records. Call this dataframe \"df\"** <br>\n",
        "Use \"index_col\" parameter to index the dataframe according to the first column. Otherwise, a new column would get created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GDXB_9GYNDV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "768fc4b4-cdc0-4abf-caf7-9818352732ee"
      },
      "source": [
        "# add code here\n",
        "classified_data_path = \"/content/gdrive/My Drive/synapse_w2/classified_data.txt\"\n",
        "\n",
        "df = pd.read_csv(classified_data_path, index_col= 0)\n",
        "df.head()"
      ],
      "execution_count": 1042,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WTT</th>\n",
              "      <th>PTI</th>\n",
              "      <th>EQW</th>\n",
              "      <th>SBI</th>\n",
              "      <th>LQE</th>\n",
              "      <th>QWG</th>\n",
              "      <th>FDJ</th>\n",
              "      <th>PJF</th>\n",
              "      <th>HQE</th>\n",
              "      <th>NXJ</th>\n",
              "      <th>TARGET CLASS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.913917</td>\n",
              "      <td>1.162073</td>\n",
              "      <td>0.567946</td>\n",
              "      <td>0.755464</td>\n",
              "      <td>0.780862</td>\n",
              "      <td>0.352608</td>\n",
              "      <td>0.759697</td>\n",
              "      <td>0.643798</td>\n",
              "      <td>0.879422</td>\n",
              "      <td>1.231409</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.635632</td>\n",
              "      <td>1.003722</td>\n",
              "      <td>0.535342</td>\n",
              "      <td>0.825645</td>\n",
              "      <td>0.924109</td>\n",
              "      <td>0.648450</td>\n",
              "      <td>0.675334</td>\n",
              "      <td>1.013546</td>\n",
              "      <td>0.621552</td>\n",
              "      <td>1.492702</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.721360</td>\n",
              "      <td>1.201493</td>\n",
              "      <td>0.921990</td>\n",
              "      <td>0.855595</td>\n",
              "      <td>1.526629</td>\n",
              "      <td>0.720781</td>\n",
              "      <td>1.626351</td>\n",
              "      <td>1.154483</td>\n",
              "      <td>0.957877</td>\n",
              "      <td>1.285597</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.234204</td>\n",
              "      <td>1.386726</td>\n",
              "      <td>0.653046</td>\n",
              "      <td>0.825624</td>\n",
              "      <td>1.142504</td>\n",
              "      <td>0.875128</td>\n",
              "      <td>1.409708</td>\n",
              "      <td>1.380003</td>\n",
              "      <td>1.522692</td>\n",
              "      <td>1.153093</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.279491</td>\n",
              "      <td>0.949750</td>\n",
              "      <td>0.627280</td>\n",
              "      <td>0.668976</td>\n",
              "      <td>1.232537</td>\n",
              "      <td>0.703727</td>\n",
              "      <td>1.115596</td>\n",
              "      <td>0.646691</td>\n",
              "      <td>1.463812</td>\n",
              "      <td>1.419167</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        WTT       PTI       EQW  ...       HQE       NXJ  TARGET CLASS\n",
              "0  0.913917  1.162073  0.567946  ...  0.879422  1.231409             1\n",
              "1  0.635632  1.003722  0.535342  ...  0.621552  1.492702             0\n",
              "2  0.721360  1.201493  0.921990  ...  0.957877  1.285597             0\n",
              "3  1.234204  1.386726  0.653046  ...  1.522692  1.153093             1\n",
              "4  1.279491  0.949750  0.627280  ...  1.463812  1.419167             1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1042
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPOM6rXpYNDW"
      },
      "source": [
        "### Exloratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J-RhwE5YNDW"
      },
      "source": [
        "**'info()' method to check the data types and number**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ27teSgYNDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f1e0f1-188e-4718-c939-e23adbb9df39"
      },
      "source": [
        "# add code here\n",
        "df.info()\n"
      ],
      "execution_count": 1043,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1000 entries, 0 to 999\n",
            "Data columns (total 11 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   WTT           1000 non-null   float64\n",
            " 1   PTI           1000 non-null   float64\n",
            " 2   EQW           1000 non-null   float64\n",
            " 3   SBI           1000 non-null   float64\n",
            " 4   LQE           1000 non-null   float64\n",
            " 5   QWG           1000 non-null   float64\n",
            " 6   FDJ           1000 non-null   float64\n",
            " 7   PJF           1000 non-null   float64\n",
            " 8   HQE           1000 non-null   float64\n",
            " 9   NXJ           1000 non-null   float64\n",
            " 10  TARGET CLASS  1000 non-null   int64  \n",
            "dtypes: float64(10), int64(1)\n",
            "memory usage: 93.8 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwSF-PxbYNDX"
      },
      "source": [
        "**Get the statistical summary of the data set** <br>\n",
        "Hint: describe()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7XvMQ5eYNDX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ca0183d0-9496-481f-a507-ba420c281f8e"
      },
      "source": [
        "# add code here\n",
        "df.describe()"
      ],
      "execution_count": 1044,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WTT</th>\n",
              "      <th>PTI</th>\n",
              "      <th>EQW</th>\n",
              "      <th>SBI</th>\n",
              "      <th>LQE</th>\n",
              "      <th>QWG</th>\n",
              "      <th>FDJ</th>\n",
              "      <th>PJF</th>\n",
              "      <th>HQE</th>\n",
              "      <th>NXJ</th>\n",
              "      <th>TARGET CLASS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.949682</td>\n",
              "      <td>1.114303</td>\n",
              "      <td>0.834127</td>\n",
              "      <td>0.682099</td>\n",
              "      <td>1.032336</td>\n",
              "      <td>0.943534</td>\n",
              "      <td>0.963422</td>\n",
              "      <td>1.071960</td>\n",
              "      <td>1.158251</td>\n",
              "      <td>1.362725</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.289635</td>\n",
              "      <td>0.257085</td>\n",
              "      <td>0.291554</td>\n",
              "      <td>0.229645</td>\n",
              "      <td>0.243413</td>\n",
              "      <td>0.256121</td>\n",
              "      <td>0.255118</td>\n",
              "      <td>0.288982</td>\n",
              "      <td>0.293738</td>\n",
              "      <td>0.204225</td>\n",
              "      <td>0.50025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.174412</td>\n",
              "      <td>0.441398</td>\n",
              "      <td>0.170924</td>\n",
              "      <td>0.045027</td>\n",
              "      <td>0.315307</td>\n",
              "      <td>0.262389</td>\n",
              "      <td>0.295228</td>\n",
              "      <td>0.299476</td>\n",
              "      <td>0.365157</td>\n",
              "      <td>0.639693</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.742358</td>\n",
              "      <td>0.942071</td>\n",
              "      <td>0.615451</td>\n",
              "      <td>0.515010</td>\n",
              "      <td>0.870855</td>\n",
              "      <td>0.761064</td>\n",
              "      <td>0.784407</td>\n",
              "      <td>0.866306</td>\n",
              "      <td>0.934340</td>\n",
              "      <td>1.222623</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.940475</td>\n",
              "      <td>1.118486</td>\n",
              "      <td>0.813264</td>\n",
              "      <td>0.676835</td>\n",
              "      <td>1.035824</td>\n",
              "      <td>0.941502</td>\n",
              "      <td>0.945333</td>\n",
              "      <td>1.065500</td>\n",
              "      <td>1.165556</td>\n",
              "      <td>1.375368</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.163295</td>\n",
              "      <td>1.307904</td>\n",
              "      <td>1.028340</td>\n",
              "      <td>0.834317</td>\n",
              "      <td>1.198270</td>\n",
              "      <td>1.123060</td>\n",
              "      <td>1.134852</td>\n",
              "      <td>1.283156</td>\n",
              "      <td>1.383173</td>\n",
              "      <td>1.504832</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.721779</td>\n",
              "      <td>1.833757</td>\n",
              "      <td>1.722725</td>\n",
              "      <td>1.634884</td>\n",
              "      <td>1.650050</td>\n",
              "      <td>1.666902</td>\n",
              "      <td>1.713342</td>\n",
              "      <td>1.785420</td>\n",
              "      <td>1.885690</td>\n",
              "      <td>1.893950</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               WTT          PTI  ...          NXJ  TARGET CLASS\n",
              "count  1000.000000  1000.000000  ...  1000.000000    1000.00000\n",
              "mean      0.949682     1.114303  ...     1.362725       0.50000\n",
              "std       0.289635     0.257085  ...     0.204225       0.50025\n",
              "min       0.174412     0.441398  ...     0.639693       0.00000\n",
              "25%       0.742358     0.942071  ...     1.222623       0.00000\n",
              "50%       0.940475     1.118486  ...     1.375368       0.50000\n",
              "75%       1.163295     1.307904  ...     1.504832       1.00000\n",
              "max       1.721779     1.833757  ...     1.893950       1.00000\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1044
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDYWYnvwYNDY"
      },
      "source": [
        "### Check the spread of the features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0hgD8wlYNDY"
      },
      "source": [
        "**Store the column names in a list**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxAYeNSzYNDY"
      },
      "source": [
        "# add code here\n",
        "columns = list(df.columns)"
      ],
      "execution_count": 1045,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3g0ISUGYNDZ"
      },
      "source": [
        "**Run a 'for' loop to draw boxplots of all the features for '0' and '1' TARGET CLASS**<br>\n",
        "Hint: Loop through each of the 10 features and draw a separate boxplot. You should have 10 boxplots in total. <br>\n",
        "Refer seaborn boxplot() "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "kORQOo9gYNDZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d0a89574-ecf9-457c-9822-20b0a4f58063"
      },
      "source": [
        "# add code here\n",
        "features = columns[:-1]\n",
        "for feat in features:\n",
        "  sns.boxplot(data= df, x= 'TARGET CLASS', y= feat)\n",
        "  plt.show()"
      ],
      "execution_count": 1046,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIFaYgUWYNDa"
      },
      "source": [
        "### Standardize the features using sklearn.preprocessing \n",
        "Why should we standardize?<br>\n",
        "Variables that are measured at different scales do not contribute equally to the model fitting & model learned function and might end up creating a bias. Thus, to deal with this potential problem feature-wise standardized (Î¼=0, Ïƒ=1) is usually used prior to model fitting.<br>\n",
        "<br>\n",
        "Go through this link for a better understanding:<br>\n",
        "https://towardsdatascience.com/how-and-why-to-standardize-your-data-996926c2c832"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzMEGA9fYNDa"
      },
      "source": [
        "**import StandardScaler from Sklearn and instantiate it to a variable called \"scaler\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVWU81uvYNDb"
      },
      "source": [
        "# add code here\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ],
      "execution_count": 1047,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlKUjW9XYNDb"
      },
      "source": [
        "**Fit only the features data to this scaler (leaving the TARGET CLASS column out) and then transform**<br>\n",
        "Hint: scaler.fit() and scaler.transform()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCbkapp4YNDb"
      },
      "source": [
        "# add code here\n",
        "df_features = df.drop(columns=['TARGET CLASS'])\n",
        "scaler.fit(df_features)\n",
        "scaled_data = scaler.transform(df_features)"
      ],
      "execution_count": 1048,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZTbl8UBYNDc"
      },
      "source": [
        "**Scaler.transform() will return an array. We need to convert this into a dataframe. Do this and add the column names to the dataframe. Call this new dataframe as \"df_feat\". Call head() on this df**<br>\n",
        "Note: The final dataframe will have the initial columns except the \"TARGET CLASS\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6DnntqtYNDc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "24bd0971-d3b8-4a3e-8ce4-6ef1f7d12435"
      },
      "source": [
        "# add code here\n",
        "cols= columns[:-1]\n",
        "df_feat = pd.DataFrame(scaled_data, columns= cols)\n",
        "df_feat.head()"
      ],
      "execution_count": 1049,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WTT</th>\n",
              "      <th>PTI</th>\n",
              "      <th>EQW</th>\n",
              "      <th>SBI</th>\n",
              "      <th>LQE</th>\n",
              "      <th>QWG</th>\n",
              "      <th>FDJ</th>\n",
              "      <th>PJF</th>\n",
              "      <th>HQE</th>\n",
              "      <th>NXJ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.123542</td>\n",
              "      <td>0.185907</td>\n",
              "      <td>-0.913431</td>\n",
              "      <td>0.319629</td>\n",
              "      <td>-1.033637</td>\n",
              "      <td>-2.308375</td>\n",
              "      <td>-0.798951</td>\n",
              "      <td>-1.482368</td>\n",
              "      <td>-0.949719</td>\n",
              "      <td>-0.643314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.084836</td>\n",
              "      <td>-0.430348</td>\n",
              "      <td>-1.025313</td>\n",
              "      <td>0.625388</td>\n",
              "      <td>-0.444847</td>\n",
              "      <td>-1.152706</td>\n",
              "      <td>-1.129797</td>\n",
              "      <td>-0.202240</td>\n",
              "      <td>-1.828051</td>\n",
              "      <td>0.636759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.788702</td>\n",
              "      <td>0.339318</td>\n",
              "      <td>0.301511</td>\n",
              "      <td>0.755873</td>\n",
              "      <td>2.031693</td>\n",
              "      <td>-0.870156</td>\n",
              "      <td>2.599818</td>\n",
              "      <td>0.285707</td>\n",
              "      <td>-0.682494</td>\n",
              "      <td>-0.377850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.982841</td>\n",
              "      <td>1.060193</td>\n",
              "      <td>-0.621399</td>\n",
              "      <td>0.625299</td>\n",
              "      <td>0.452820</td>\n",
              "      <td>-0.267220</td>\n",
              "      <td>1.750208</td>\n",
              "      <td>1.066491</td>\n",
              "      <td>1.241325</td>\n",
              "      <td>-1.026987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.139275</td>\n",
              "      <td>-0.640392</td>\n",
              "      <td>-0.709819</td>\n",
              "      <td>-0.057175</td>\n",
              "      <td>0.822886</td>\n",
              "      <td>-0.936773</td>\n",
              "      <td>0.596782</td>\n",
              "      <td>-1.472352</td>\n",
              "      <td>1.040772</td>\n",
              "      <td>0.276510</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        WTT       PTI       EQW  ...       PJF       HQE       NXJ\n",
              "0 -0.123542  0.185907 -0.913431  ... -1.482368 -0.949719 -0.643314\n",
              "1 -1.084836 -0.430348 -1.025313  ... -0.202240 -1.828051  0.636759\n",
              "2 -0.788702  0.339318  0.301511  ...  0.285707 -0.682494 -0.377850\n",
              "3  0.982841  1.060193 -0.621399  ...  1.066491  1.241325 -1.026987\n",
              "4  1.139275 -0.640392 -0.709819  ... -1.472352  1.040772  0.276510\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1049
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWiXgySxYNDd"
      },
      "source": [
        "### Train/Test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgJQPOfXYNDd"
      },
      "source": [
        "**Set X to be equal to df_feat and set y accordingly. As you know, X contains our training features and y contains our target.**<br>\n",
        "Hint: y can be taken directly from the initaial dataframe \"df\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W94s-2-jYNDd"
      },
      "source": [
        "# add code here\n",
        "\n",
        "X = df_feat\n",
        "y = df['TARGET CLASS']"
      ],
      "execution_count": 1050,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tyZdg0nYNDd"
      },
      "source": [
        "**Import train_test_split function from scikit-learn**<br>\n",
        "**Create X and y train and test splits in one command using a test size of 0.3 and a random seed**<br>\n",
        "They should be called X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiNlmT2IYNDe"
      },
      "source": [
        "# add code here\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 1051,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6tS1j4iYNDe"
      },
      "source": [
        "### Model fit and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A_LeaNAYNDe"
      },
      "source": [
        "**import KNeighborsClassifier from sklearn and initialize it with neighbours = 1. Fit this on X_train and y_train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaSJJTYDYNDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79fcabff-cb27-4cdd-b374-5133b8e7a815"
      },
      "source": [
        "# add code here\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=1)\n",
        "neigh.fit(X_train, y_train)"
      ],
      "execution_count": 1052,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {},
          "execution_count": 1052
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAEVkt6LYNDf"
      },
      "source": [
        "**Using this fitted model, predict on X_test. Store these predictions in variable called pred.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsnjjXaMYNDf"
      },
      "source": [
        "# add code here\n",
        "pred = neigh.predict(X_test)"
      ],
      "execution_count": 1053,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IcCOyuOYNDf"
      },
      "source": [
        "**Let us check how correct these predictions are.<br>\n",
        "Print a classification report of y_test and pred**<br>\n",
        "Hint: sklearn classification_report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC-20WeuYNDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5af1116-51ac-440c-dbfd-b34b14fe9f1c"
      },
      "source": [
        "# add code here\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 1054,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93       142\n",
            "           1       0.95      0.93      0.94       158\n",
            "\n",
            "    accuracy                           0.94       300\n",
            "   macro avg       0.94      0.94      0.94       300\n",
            "weighted avg       0.94      0.94      0.94       300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exGvX0C5YNDg"
      },
      "source": [
        "**Print the accuracy using numpy and round it to 3 decimal places.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSoOx6MiYNDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f19c3707-a7ba-46ad-b50e-c3d6ae9dec19"
      },
      "source": [
        "# add code here\n",
        "total = y_test.size\n",
        "y_test_np = y_test.to_numpy()\n",
        "accuracy = round(np.mean(y_test_np == pred) , 3)\n",
        "accuracy\n",
        "\n"
      ],
      "execution_count": 1055,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.937"
            ]
          },
          "metadata": {},
          "execution_count": 1055
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWjjrBrbYNDh"
      },
      "source": [
        "### Choosing optimal 'k'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT_5lBDVYNDh"
      },
      "source": [
        "**Above, we chose n_neighbours to be equal to 1. Choosing a small value of K leads to unstable decision boundaries. <br>\n",
        "We need to select n_neighbours by calculating the accuracy for every value of n from 1 to 60 and then choosing the one which gives the highest accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPKm3inZYNDh"
      },
      "source": [
        "# Do the same as we did above, but this time make a loop from n = 1 to n = 60 and append the accuracy\n",
        "# for each in a list\n",
        "\n",
        "# add code here\n",
        "\n",
        "# accuracy = []\n",
        "# for i in range(1,61):\n",
        "#   neigh = KNeighborsClassifier(n_neighbors=i)\n",
        "#   neigh.fit(X_train, y_train)\n",
        "#   pred = neigh.predict(X_test)\n",
        "#   accuracy.append(round(np.mean(y_test_np == pred) , 3))"
      ],
      "execution_count": 1056,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfQCwq_DwRsI"
      },
      "source": [
        "**K-Fold**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B5dtDEMwZcf",
        "outputId": "f569503a-a8f2-4a8d-c1c4-46c350ad7edd"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from statistics import mean\n",
        "\n",
        "\n",
        "accuracy_knn = []\n",
        "kf = KFold(n_splits=9)\n",
        "for j in range(1,61):\n",
        "  scores= []\n",
        "  knn = KNeighborsClassifier(n_neighbors=j, weights='distance')\n",
        "  for train_index, test_index in kf.split(X_train):\n",
        "    X_train_kf, X_test_kf = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "    y_train_kf, y_test_kf = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "    knn.fit(X_train_kf, y_train_kf)\n",
        "    knn_score = knn.score(X_test_kf, y_test_kf)\n",
        "    scores.append(knn_score)\n",
        "  accuracy_knn.append(mean(scores))\n",
        "optimum_k_acc = max(accuracy_knn)\n",
        "accuracy_knn.index(optimum_k_acc)\n"
      ],
      "execution_count": 1057,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 1057
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1FGZ9FpKmkg",
        "outputId": "70e33011-09d5-4717-9578-e9c21c190cce"
      },
      "source": [
        "kf = KFold(n_splits=9)\n",
        "scores= []\n",
        "knn = KNeighborsClassifier(n_neighbors=31, weights='distance')\n",
        "for train_index, test_index in kf.split(X_train):\n",
        "  X_train_kf, X_test_kf = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "  y_train_kf, y_test_kf = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "  knn.fit(X_train_kf, y_train_kf)\n",
        "  knn_score = knn.score(X_test_kf, y_test_kf)\n",
        "  scores.append(knn_score)\n",
        "print(mean(scores))"
      ],
      "execution_count": 1058,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.92999592999593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXu8svwVXLlz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LUl_JMUYNDi"
      },
      "source": [
        "**Plot a graph of K value vs Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvsbINxsYNDi"
      },
      "source": [
        "# add code here\n",
        "# k_values = list(range(1,61))\n",
        "# plt.plot(k_values, accuracy)"
      ],
      "execution_count": 1059,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO4KK1WEYNDi"
      },
      "source": [
        "**Choose the best value of n_neighbours and give a reason why and also print the accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWf5hh-jYNDj"
      },
      "source": [
        "# add code here \n",
        "# optimum_accuracy = max(accuracy) #highest accuracy\n",
        "# k_optimum = accuracy.index(optimum_accuracy) +1\n",
        "# print('Optimum K=', k_optimum, '\\nOptimum accuracy=', optimum_accuracy)"
      ],
      "execution_count": 1060,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMuYP87E2saO"
      },
      "source": [
        "**Test accuracy and Train accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HAymn9v24QN",
        "outputId": "3c1617a6-1f62-4d9f-8d93-fc85370bddd7"
      },
      "source": [
        "knn.score(X_test, y_test)\n",
        "print('Test accuracy=', round(knn.score(X_test, y_test), 3))\n",
        "print('Train accuracy=', round(mean(scores), 3))"
      ],
      "execution_count": 1061,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy= 0.947\n",
            "Train accuracy= 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4CBOAiOd9is"
      },
      "source": [
        "# 3). Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXCHg4IQewph"
      },
      "source": [
        "<b>read the titanic_data.csv using pandas and show the dataframe</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dGi9n5meB94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "ab934222-92a3-44c7-84e3-e127129605c7"
      },
      "source": [
        "#write code here\n",
        "titanic_data_path = \"/content/gdrive/My Drive/synapse_w2/titanic_data.csv\"\n",
        "\n",
        "df = pd.read_csv(titanic_data_path)\n",
        "df"
      ],
      "execution_count": 1062,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0              1         0       3  ...   7.2500   NaN         S\n",
              "1              2         1       1  ...  71.2833   C85         C\n",
              "2              3         1       3  ...   7.9250   NaN         S\n",
              "3              4         1       1  ...  53.1000  C123         S\n",
              "4              5         0       3  ...   8.0500   NaN         S\n",
              "..           ...       ...     ...  ...      ...   ...       ...\n",
              "886          887         0       2  ...  13.0000   NaN         S\n",
              "887          888         1       1  ...  30.0000   B42         S\n",
              "888          889         0       3  ...  23.4500   NaN         S\n",
              "889          890         1       1  ...  30.0000  C148         C\n",
              "890          891         0       3  ...   7.7500   NaN         Q\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1062
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph135_ppe2I4"
      },
      "source": [
        "<b>Write a function which accepts a dataframe, preprocesses the data (use task 1 notebook) and returns a new dataframe. </b> <br>\n",
        "you may need a helper function for normalizing data so feel free to define that as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEgFQI3se0dn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "69d8ad83-e0e8-4455-e7c1-193e02f42498"
      },
      "source": [
        "def titanic_preprocessing_pipeline(df):\n",
        "  #enter preprocessing steps as done in task 1\n",
        "  #make sure the preprocessed dataframe looks like the output in task 1\n",
        "  #return the dataframe\n",
        "  #remove this line after writing the code\n",
        "\n",
        "  #Creating Title feature\n",
        "  import re\n",
        "  titles = []\n",
        "  for name in df['Name']:\n",
        "    title = re.search('(\\w+)\\.', name).group(1)\n",
        "    titles.append(title)\n",
        "  df['Title'] = titles\n",
        "\n",
        "  #Removing unnecessary columns\n",
        "  train_df = df.drop(columns=['PassengerId', 'Ticket', 'Name'])\n",
        "  \n",
        "  #Nan Analysis\n",
        "  nan_list= []\n",
        "  for col in train_df.columns:\n",
        "    nan_count= train_df[col].isnull().sum()\n",
        "    nan_percent = nan_count *100/len(train_df[col])\n",
        "    nan_list.append([col, nan_percent])\n",
        "  nan_df = pd.DataFrame(nan_list, columns=['Column','NaN percent'])\n",
        "  discard = nan_df.loc[nan_df['NaN percent'] >50 ]\n",
        "  train_df.drop(columns=discard['Column'], inplace= True)\n",
        "  train_df['Embarked'] = train_df['Embarked'].replace(np.nan, train_df['Embarked'].mode()[0])\n",
        "  train_df['Age'] = train_df['Age'].replace(np.nan, train_df['Age'].mean())\n",
        "\n",
        "  #Adding features\n",
        "  family_members= []\n",
        "  for i in range(0, len(train_df)):\n",
        "    sum = train_df['SibSp'][i] +train_df['Parch'][i]\n",
        "    family_members.append(sum)\n",
        "  train_df['Family_members']= family_members\n",
        "  train_df.drop(columns=['SibSp', 'Parch'], inplace= True)\n",
        "\n",
        "  #standardization and normalization\n",
        "  from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "  train_df[['Age']] = MinMaxScaler().fit_transform(train_df[['Age']])\n",
        "  train_df[['Fare']] = StandardScaler().fit_transform(train_df[['Family_members']])\n",
        "  train_df[['Family_members']] = MinMaxScaler().fit_transform(train_df[['Family_members']])\n",
        "\n",
        "  #One hot encoding\n",
        "  train_df= pd.get_dummies(train_df, columns= ['Pclass','Sex','Title','Embarked'])\n",
        "  return train_df\n",
        "\n",
        "df = titanic_preprocessing_pipeline(df)\n",
        "df"
      ],
      "execution_count": 1063,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Family_members</th>\n",
              "      <th>Pclass_1</th>\n",
              "      <th>Pclass_2</th>\n",
              "      <th>Pclass_3</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Title_Capt</th>\n",
              "      <th>Title_Col</th>\n",
              "      <th>Title_Countess</th>\n",
              "      <th>Title_Don</th>\n",
              "      <th>Title_Dr</th>\n",
              "      <th>Title_Jonkheer</th>\n",
              "      <th>Title_Lady</th>\n",
              "      <th>Title_Major</th>\n",
              "      <th>Title_Master</th>\n",
              "      <th>Title_Miss</th>\n",
              "      <th>Title_Mlle</th>\n",
              "      <th>Title_Mme</th>\n",
              "      <th>Title_Mr</th>\n",
              "      <th>Title_Mrs</th>\n",
              "      <th>Title_Ms</th>\n",
              "      <th>Title_Rev</th>\n",
              "      <th>Title_Sir</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>0.059160</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.472229</td>\n",
              "      <td>0.059160</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>-0.560975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0.059160</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>-0.560975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>0.334004</td>\n",
              "      <td>-0.560975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>0.233476</td>\n",
              "      <td>-0.560975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>0.367921</td>\n",
              "      <td>1.299429</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>-0.560975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>0.396833</td>\n",
              "      <td>-0.560975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Survived       Age      Fare  ...  Embarked_C  Embarked_Q  Embarked_S\n",
              "0           0  0.271174  0.059160  ...           0           0           1\n",
              "1           1  0.472229  0.059160  ...           1           0           0\n",
              "2           1  0.321438 -0.560975  ...           0           0           1\n",
              "3           1  0.434531  0.059160  ...           0           0           1\n",
              "4           0  0.434531 -0.560975  ...           0           0           1\n",
              "..        ...       ...       ...  ...         ...         ...         ...\n",
              "886         0  0.334004 -0.560975  ...           0           0           1\n",
              "887         1  0.233476 -0.560975  ...           0           0           1\n",
              "888         0  0.367921  1.299429  ...           0           0           1\n",
              "889         1  0.321438 -0.560975  ...           1           0           0\n",
              "890         0  0.396833 -0.560975  ...           0           1           0\n",
              "\n",
              "[891 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1063
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rlnz6P-xh1SA"
      },
      "source": [
        "<b>extract the y label (survived) from the dataframe and store it in a new variable</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0WuPt4DhpOx"
      },
      "source": [
        "#write code here\n",
        "y = df['Survived']"
      ],
      "execution_count": 1064,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzP6YHDTiC--"
      },
      "source": [
        "<b>remove the y_label (survived) from the dataframe</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI0KwhYHiIBT"
      },
      "source": [
        "#write code here\n",
        "X = df.drop(columns=['Survived'])"
      ],
      "execution_count": 1065,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ut650pSiIw1"
      },
      "source": [
        "<b>Split the data into train and test. (do a split in the ratio 30:70)</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phcn_hG7iRIN"
      },
      "source": [
        "#write code here\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify= y)"
      ],
      "execution_count": 1066,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqZl02RsiSbJ"
      },
      "source": [
        "<b>Now that you have the entire preprocessed and split data, implement the decision tree algorithm from sklearn and fit it to this dataset</b> <br>\n",
        "\n",
        "Make sure that you play with the hyperparameters to get a good result. You can even use bagging and boosting methods like random forest or adaboost to improve your accuracy. Visualize results, try different hyperparameters by using a loop, GET CREATIVE!<br>\n",
        "\n",
        "Machine learning is an iteritive process. You will have to keep playing with hyperparameters and algorithms. No fixed algorithm will work on a fixed dataset.\n",
        "\n",
        "Take this up as a challenge. The person with the best accuracy wins the round!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVNqRQx2j6iO"
      },
      "source": [
        "<b>Note that the accuracy on the test set will be considered and brownie points for not overfitting the model in the process</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulNAgERBjytd"
      },
      "source": [
        "#write code here\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# dt_model = DecisionTreeClassifier(random_state = 42)\n",
        "# dt_model.fit(X_train, y_train)\n",
        "# print(dt_model.score(X_train, y_train))\n",
        "# dt_model.score(X_test, y_test)"
      ],
      "execution_count": 1067,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGezwHeYrwen"
      },
      "source": [
        "# train_accuracy = []\n",
        "# test_accuracy = []\n",
        "# for i in range(1,41):\n",
        "#   dt_model = DecisionTreeClassifier(random_state = 42, max_depth= i)\n",
        "#   dt_model.fit(X_train, y_train)\n",
        "#   train_accuracy.append(dt_model.score(X_train, y_train))\n",
        "#   test_accuracy.append(dt_model.score(X_test, y_test))\n",
        "\n",
        "# frame = pd.DataFrame({'max_depth': range(1,41), 'Train accuracy': train_accuracy, 'Test accuracy': test_accuracy})\n",
        "# plt.figure(figsize=(10,5))\n",
        "# plt.plot(frame['max_depth'], frame['Train accuracy'], marker='o')\n",
        "# plt.plot(frame['max_depth'], frame['Test accuracy'], marker='o')\n"
      ],
      "execution_count": 1068,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuwA192WwRDC"
      },
      "source": [
        "# dt_model = DecisionTreeClassifier(random_state = 42, max_depth= 3)\n",
        "# dt_model.fit(X_train, y_train)\n",
        "# print(dt_model.score(X_train, y_train))\n",
        "# dt_model.score(X_test, y_test)"
      ],
      "execution_count": 1069,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ks90WDqtuf_"
      },
      "source": [
        "# from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Adamodel = AdaBoostClassifier(random_state = 42)\n",
        "# Adamodel.fit(X_train, y_train)\n",
        "# print(Adamodel.score(X_train, y_train))\n",
        "# Adamodel.score(X_test, y_test)"
      ],
      "execution_count": 1070,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH6DqHydw3IC"
      },
      "source": [
        "# train_accuracy = []\n",
        "# test_accuracy = []\n",
        "# for i in range(1,41):\n",
        "#   Adamodel = AdaBoostClassifier(random_state = 42, n_estimators=i, learning_rate=1)\n",
        "#   Adamodel.fit(X_train, y_train)\n",
        "#   train_accuracy.append(Adamodel.score(X_train, y_train))\n",
        "#   test_accuracy.append(Adamodel.score(X_test, y_test))\n",
        "# frame = pd.DataFrame({'n_estimators': range(1,41), 'Train accuracy': train_accuracy, 'Test accuracy': test_accuracy})\n",
        "# plt.figure(figsize=(10,5))\n",
        "# plt.plot(frame['n_estimators'], frame['Train accuracy'], marker='o')\n",
        "# plt.plot(frame['n_estimators'], frame['Test accuracy'], marker='o')\n"
      ],
      "execution_count": 1071,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38aACWH47w84"
      },
      "source": [
        "# Adamodel = AdaBoostClassifier(random_state = 42, n_estimators=14, learning_rate=1)\n",
        "# Adamodel.fit(X_train, y_train)\n",
        "# print(Adamodel.score(X_train, y_train))\n",
        "# Adamodel.score(X_test, y_test)"
      ],
      "execution_count": 1072,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF532_NbzERp"
      },
      "source": [
        "# train_accuracy = []\n",
        "# test_accuracy = []\n",
        "# for i in range(1,31):\n",
        "#   Adamodel = AdaBoostClassifier(random_state = 42, n_estimators=14, learning_rate=i)\n",
        "#   Adamodel.fit(X_train, y_train)\n",
        "#   train_accuracy.append(Adamodel.score(X_train, y_train))\n",
        "#   test_accuracy.append(Adamodel.score(X_test, y_test))\n",
        "# frame = pd.DataFrame({'n_estimators': range(1,31), 'Train accuracy': train_accuracy, 'Test accuracy': test_accuracy})\n",
        "# plt.figure(figsize=(10,5))\n",
        "# plt.plot(frame['n_estimators'], frame['Train accuracy'], marker='o')\n",
        "# plt.plot(frame['n_estimators'], frame['Test accuracy'], marker='o')\n"
      ],
      "execution_count": 1073,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImEEa3NI7894"
      },
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# rfmodel = RandomForestClassifier(random_state = 42)\n",
        "# rfmodel.fit(X_train, y_train)\n",
        "# print(rfmodel.score(X_train, y_train))\n",
        "# rfmodel.score(X_test, y_test)"
      ],
      "execution_count": 1074,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_j7QgHj-ApK"
      },
      "source": [
        "# train_accuracy = []\n",
        "# test_accuracy = []\n",
        "# for i in range(1,41):\n",
        "#   rfmodel = RandomForestClassifier(random_state = 42, n_estimators=i)\n",
        "#   rfmodel.fit(X_train, y_train)\n",
        "#   train_accuracy.append(rfmodel.score(X_train, y_train))\n",
        "#   test_accuracy.append(rfmodel.score(X_test, y_test))\n",
        "# frame = pd.DataFrame({'n_estimators': range(1,41), 'Train accuracy': train_accuracy, 'Test accuracy': test_accuracy})\n",
        "# plt.figure(figsize=(10,5))\n",
        "# plt.plot(frame['n_estimators'], frame['Train accuracy'], marker='o')\n",
        "# plt.plot(frame['n_estimators'], frame['Test accuracy'], marker='o')"
      ],
      "execution_count": 1075,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgXG2TFz-ho8"
      },
      "source": [
        "# rfmodel = RandomForestClassifier(random_state = 42, n_estimators=16)\n",
        "# rfmodel.fit(X_train, y_train)\n",
        "# print(rfmodel.score(X_train, y_train))\n",
        "# rfmodel.score(X_test, y_test)"
      ],
      "execution_count": 1076,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqeshHSYFizS"
      },
      "source": [
        "# train_accuracy = []\n",
        "# test_accuracy = []\n",
        "# for i in range(1,41):\n",
        "#   rfmodel = RandomForestClassifier(random_state = 42, n_estimators=16, min_samples_leaf=i)\n",
        "#   rfmodel.fit(X_train, y_train)\n",
        "#   train_accuracy.append(rfmodel.score(X_train, y_train))\n",
        "#   test_accuracy.append(rfmodel.score(X_test, y_test))\n",
        "# frame = pd.DataFrame({'Hyperparameter': range(1,41), 'Train accuracy': train_accuracy, 'Test accuracy': test_accuracy})\n",
        "# plt.figure(figsize=(10,5))\n",
        "# plt.plot(frame['Hyperparameter'], frame['Train accuracy'], marker='o')\n",
        "# plt.plot(frame['Hyperparameter'], frame['Test accuracy'], marker='o')"
      ],
      "execution_count": 1077,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERZdObNZF_Gc"
      },
      "source": [
        "# rfmodel = RandomForestClassifier(random_state = 42, n_estimators=16, min_samples_leaf=4)\n",
        "# rfmodel.fit(X_train, y_train)\n",
        "# print(rfmodel.score(X_train, y_train))\n",
        "# rfmodel.score(X_test, y_test)"
      ],
      "execution_count": 1078,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPt_4hn_GUMA"
      },
      "source": [
        "# train_accuracy = []\n",
        "# test_accuracy = []\n",
        "# for i in range(1,41):\n",
        "#   rfmodel = RandomForestClassifier(random_state = 42, n_estimators=16, min_samples_leaf=4, max_depth= i)\n",
        "#   rfmodel.fit(X_train, y_train)\n",
        "#   train_accuracy.append(rfmodel.score(X_train, y_train))\n",
        "#   test_accuracy.append(rfmodel.score(X_test, y_test))\n",
        "# frame = pd.DataFrame({'Hyperparameter': range(1,41), 'Train accuracy': train_accuracy, 'Test accuracy': test_accuracy})\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# plt.plot(frame['Hyperparameter'], frame['Train accuracy'], marker='o')\n",
        "# plt.plot(frame['Hyperparameter'], frame['Test accuracy'], marker='o')"
      ],
      "execution_count": 1079,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2N8BurxIa0P"
      },
      "source": [
        "# rfmodel = RandomForestClassifier(random_state = 42, n_estimators=16, min_samples_leaf=4, max_depth= 16)\n",
        "# rfmodel.fit(X_train, y_train)"
      ],
      "execution_count": 1080,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyQwgeMsHi_Z"
      },
      "source": [
        "**KFold**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-xFpE49buvF"
      },
      "source": [
        "def populate_dict(i, k, train_accuracy, test_accuracy, n, preds):\n",
        "  d = {}\n",
        "  d[\"n_estimators\"] = n\n",
        "  d[\"max_depth\"] = i \n",
        "  d[\"min_samples_leaf\"] = k\n",
        "  d[\"test_acc\"] = test_accuracy\n",
        "  d[\"train_acc\"] = train_accuracy\n",
        "  diff = abs(test_accuracy-train_accuracy)\n",
        "  d[\"diff\"] = diff\n",
        "  d[\"preds\"] = preds\n",
        "  return d"
      ],
      "execution_count": 1081,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSqJlDNHLaDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0da21a7-32fb-4450-8995-822f94bc37f5"
      },
      "source": [
        "max_depth_list = [5, 10, 15, 20, 25]\n",
        "min_samples_split_list = [20, 40, 60, 80, 100]\n",
        "min_samples_leaf_list = [1, 2, 3, 4, 5]\n",
        "n_estimators_list = [5, 10, 15, 20]\n",
        "\n",
        "\n",
        "metric_list = []\n",
        "kf = KFold(n_splits=5)\n",
        "for n in n_estimators_list:\n",
        "  for i in max_depth_list:\n",
        "    for k in min_samples_leaf_list:\n",
        "      scores= []\n",
        "      rf = RandomForestClassifier(random_state = 42, max_depth = i, min_samples_leaf = k, n_estimators = n)\n",
        "\n",
        "      for train_index, test_index in kf.split(X_train):\n",
        "        X_train_kf, X_test_kf = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "        y_train_kf, y_test_kf = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "        rf.fit(X_train_kf, y_train_kf)\n",
        "        rf_score = rf.score(X_test_kf, y_test_kf)\n",
        "        scores.append(rf_score)\n",
        "\n",
        "      train_accuracy = mean(scores)\n",
        "      preds = rf.predict(X_test)\n",
        "      test_accuracy = rf.score(X_test, y_test)\n",
        "      d = populate_dict(i, k, train_accuracy, test_accuracy, n, preds)\n",
        "      metric_list.append(d)\n",
        "sorted(metric_list, key=lambda d : d[\"diff\"])"
      ],
      "execution_count": 1082,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'diff': 0.00030563312469911175,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8056645161290322},\n",
              " {'diff': 0.00030563312469911175,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8056645161290322},\n",
              " {'diff': 0.00030563312469911175,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8056645161290322},\n",
              " {'diff': 0.0006935002407317814,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7761194029850746,\n",
              "  'train_acc': 0.7768129032258064},\n",
              " {'diff': 0.0006935002407317814,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7761194029850746,\n",
              "  'train_acc': 0.7768129032258064},\n",
              " {'diff': 0.0007064034665382746,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7761194029850746,\n",
              "  'train_acc': 0.7768258064516129},\n",
              " {'diff': 0.0013132402503610585,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8184774193548386},\n",
              " {'diff': 0.0013132402503610585,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8184774193548386},\n",
              " {'diff': 0.0013201733269138094,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8072903225806451},\n",
              " {'diff': 0.0013201733269138094,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8072903225806451},\n",
              " {'diff': 0.0013201733269138094,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8072903225806451},\n",
              " {'diff': 0.001355416466056858,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8134328358208955,\n",
              "  'train_acc': 0.8120774193548387},\n",
              " {'diff': 0.0019125662012517974,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8152516129032258},\n",
              " {'diff': 0.0023630235917189157,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8120645161290323},\n",
              " {'diff': 0.002375926817525298,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8120774193548387},\n",
              " {'diff': 0.002375926817525298,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8120774193548387},\n",
              " {'diff': 0.002405199807414604,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8184903225806451},\n",
              " {'diff': 0.0024439094848339726,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8184516129032258},\n",
              " {'diff': 0.0024439094848339726,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8184516129032258},\n",
              " {'diff': 0.0025263360616273323,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7873134328358209,\n",
              "  'train_acc': 0.7847870967741936},\n",
              " {'diff': 0.002900337024554611,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8200645161290322},\n",
              " {'diff': 0.002900337024554611,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8200645161290322},\n",
              " {'diff': 0.002900337024554611,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8200645161290322},\n",
              " {'diff': 0.0029365430909966683,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8246268656716418,\n",
              "  'train_acc': 0.8216903225806451},\n",
              " {'diff': 0.0029494463168030505,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8246268656716418,\n",
              "  'train_acc': 0.8216774193548387},\n",
              " {'diff': 0.002968319691863286,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8134328358208955,\n",
              "  'train_acc': 0.8104645161290323},\n",
              " {'diff': 0.00391834376504574,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7985074626865671,\n",
              "  'train_acc': 0.8024258064516129},\n",
              " {'diff': 0.004005199807414539,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8168903225806452},\n",
              " {'diff': 0.0040369764082811566,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8056645161290322},\n",
              " {'diff': 0.0040369764082811566,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8056645161290322},\n",
              " {'diff': 0.004373230621088187,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7723880597014925,\n",
              "  'train_acc': 0.7767612903225807},\n",
              " {'diff': 0.004373230621088187,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7723880597014925,\n",
              "  'train_acc': 0.7767612903225807},\n",
              " {'diff': 0.004468560423688039,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8104387096774194},\n",
              " {'diff': 0.004549446316803096,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8246268656716418,\n",
              "  'train_acc': 0.8200774193548387},\n",
              " {'diff': 0.005044583533943103,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8134328358208955,\n",
              "  'train_acc': 0.8184774193548386},\n",
              " {'diff': 0.005607703418391896,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8265032258064516},\n",
              " {'diff': 0.006120173326913836,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8120903225806452},\n",
              " {'diff': 0.006149446316803142,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8246268656716418,\n",
              "  'train_acc': 0.8184774193548386},\n",
              " {'diff': 0.006549253731343296,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7798507462686567,\n",
              "  'train_acc': 0.7864},\n",
              " {'diff': 0.006686759749638838,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8104774193548387},\n",
              " {'diff': 0.006686759749638838,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8104774193548387},\n",
              " {'diff': 0.007175926817525324,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8168774193548387},\n",
              " {'diff': 0.007175926817525324,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8168774193548387},\n",
              " {'diff': 0.007294559460760741,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7985074626865671,\n",
              "  'train_acc': 0.7912129032258064},\n",
              " {'diff': 0.0073134328358208656,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7873134328358209,\n",
              "  'train_acc': 0.78},\n",
              " {'diff': 0.0073134328358208656,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7873134328358209,\n",
              "  'train_acc': 0.78},\n",
              " {'diff': 0.008293692826191634,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8283582089552238,\n",
              "  'train_acc': 0.8200645161290322},\n",
              " {'diff': 0.008799229658160823,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.832089552238806,\n",
              "  'train_acc': 0.8232903225806452},\n",
              " {'diff': 0.008799229658160823,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.832089552238806,\n",
              "  'train_acc': 0.8232903225806452},\n",
              " {'diff': 0.008831006259027552,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8120645161290322},\n",
              " {'diff': 0.009320173326913817,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8152903225806452},\n",
              " {'diff': 0.009345979778526692,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.815316129032258},\n",
              " {'diff': 0.010375926817525305,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8200774193548387},\n",
              " {'diff': 0.01040173326913818,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8201032258064516},\n",
              " {'diff': 0.010412132883967251,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.832089552238806,\n",
              "  'train_acc': 0.8216774193548387},\n",
              " {'diff': 0.01091766971593644,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.835820895522388,\n",
              "  'train_acc': 0.8249032258064516},\n",
              " {'diff': 0.011431680308136682,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8134328358208955,\n",
              "  'train_acc': 0.8248645161290322},\n",
              " {'diff': 0.011438613384689433,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8136774193548387},\n",
              " {'diff': 0.01151949927780449,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8283582089552238,\n",
              "  'train_acc': 0.8168387096774193},\n",
              " {'diff': 0.01151949927780449,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8283582089552238,\n",
              "  'train_acc': 0.8168387096774193},\n",
              " {'diff': 0.01151949927780449,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8283582089552238,\n",
              "  'train_acc': 0.8168387096774193},\n",
              " {'diff': 0.012481463649494429,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8184516129032258},\n",
              " {'diff': 0.012494366875300922,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8184645161290323},\n",
              " {'diff': 0.01359922965816085,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.832089552238806,\n",
              "  'train_acc': 0.8184903225806451},\n",
              " {'diff': 0.013631006259027467,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8072645161290323},\n",
              " {'diff': 0.013631006259027467,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8072645161290323},\n",
              " {'diff': 0.013631006259027467,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8072645161290323},\n",
              " {'diff': 0.014638613384689414,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8168774193548387},\n",
              " {'diff': 0.01516995666827159,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7985074626865671,\n",
              "  'train_acc': 0.8136774193548387},\n",
              " {'diff': 0.015231006259027513,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8056645161290322},\n",
              " {'diff': 0.01559903707270105,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7723880597014925,\n",
              "  'train_acc': 0.7879870967741935},\n",
              " {'diff': 0.01560597014925369,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7611940298507462,\n",
              "  'train_acc': 0.7767999999999999},\n",
              " {'diff': 0.016212806933076473,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8184516129032258},\n",
              " {'diff': 0.016642850264805054,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.753731343283582,\n",
              "  'train_acc': 0.7703741935483871},\n",
              " {'diff': 0.016769956668271524,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7985074626865671,\n",
              "  'train_acc': 0.8152774193548387},\n",
              " {'diff': 0.017838613384689395,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8200774193548387},\n",
              " {'diff': 0.017838613384689395,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8200774193548387},\n",
              " {'diff': 0.01786441983630227,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8201032258064516},\n",
              " {'diff': 0.01824285026480499,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.753731343283582,\n",
              "  'train_acc': 0.771974193548387},\n",
              " {'diff': 0.01828059701492535,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7761194029850746,\n",
              "  'train_acc': 0.7944},\n",
              " {'diff': 0.018962349542609558,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8246268656716418,\n",
              "  'train_acc': 0.8056645161290322},\n",
              " {'diff': 0.019464419836302316,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8217032258064516},\n",
              " {'diff': 0.019464419836302316,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8217032258064516},\n",
              " {'diff': 0.019474819451131498,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8395522388059702,\n",
              "  'train_acc': 0.8200774193548387},\n",
              " {'diff': 0.01991237361579201,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7873134328358209,\n",
              "  'train_acc': 0.8072258064516129},\n",
              " {'diff': 0.01999325950890707,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8432835820895522,\n",
              "  'train_acc': 0.8232903225806452},\n",
              " {'diff': 0.01999325950890707,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8432835820895522,\n",
              "  'train_acc': 0.8232903225806452},\n",
              " {'diff': 0.01999325950890707,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8432835820895522,\n",
              "  'train_acc': 0.8232903225806452},\n",
              " {'diff': 0.020540009629272937,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7947761194029851,\n",
              "  'train_acc': 0.815316129032258},\n",
              " {'diff': 0.020540009629272937,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7947761194029851,\n",
              "  'train_acc': 0.815316129032258},\n",
              " {'diff': 0.024806162734713588,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8432835820895522,\n",
              "  'train_acc': 0.8184774193548386},\n",
              " {'diff': 0.024876649012999574,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.832089552238806,\n",
              "  'train_acc': 0.8072129032258064},\n",
              " {'diff': 0.024876649012999574,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.832089552238806,\n",
              "  'train_acc': 0.8072129032258064},\n",
              " {'diff': 0.029595763119884433,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7985074626865671,\n",
              "  'train_acc': 0.8281032258064516},\n",
              " {'diff': 0.033193066923447256,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7611940298507462,\n",
              "  'train_acc': 0.7943870967741935},\n",
              " {'diff': 0.033314203177660096,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7947761194029851,\n",
              "  'train_acc': 0.8280903225806452},\n",
              " {'diff': 0.033314203177660096,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7947761194029851,\n",
              "  'train_acc': 0.8280903225806452},\n",
              " {'diff': 0.03338218584496866,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.835820895522388,\n",
              "  'train_acc': 0.8024387096774194},\n",
              " {'diff': 0.03338218584496866,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.835820895522388,\n",
              "  'train_acc': 0.8024387096774194},\n",
              " {'diff': 0.039189792970630744,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7873134328358209,\n",
              "  'train_acc': 0.8265032258064516}]"
            ]
          },
          "metadata": {},
          "execution_count": 1082
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQxopk4urDth",
        "outputId": "2cbf78b9-bdcf-4d92-86f7-3452e028a5d4"
      },
      "source": [
        "sorted_testacc = sorted(metric_list, key=lambda d : d[\"test_acc\"], reverse= True)\n",
        "sorted_testacc"
      ],
      "execution_count": 1083,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'diff': 0.01999325950890707,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8432835820895522,\n",
              "  'train_acc': 0.8232903225806452},\n",
              " {'diff': 0.01999325950890707,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8432835820895522,\n",
              "  'train_acc': 0.8232903225806452},\n",
              " {'diff': 0.01999325950890707,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8432835820895522,\n",
              "  'train_acc': 0.8232903225806452},\n",
              " {'diff': 0.024806162734713588,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8432835820895522,\n",
              "  'train_acc': 0.8184774193548386},\n",
              " {'diff': 0.019474819451131498,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8395522388059702,\n",
              "  'train_acc': 0.8200774193548387},\n",
              " {'diff': 0.03338218584496866,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.835820895522388,\n",
              "  'train_acc': 0.8024387096774194},\n",
              " {'diff': 0.03338218584496866,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.835820895522388,\n",
              "  'train_acc': 0.8024387096774194},\n",
              " {'diff': 0.01091766971593644,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.835820895522388,\n",
              "  'train_acc': 0.8249032258064516},\n",
              " {'diff': 0.024876649012999574,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.832089552238806,\n",
              "  'train_acc': 0.8072129032258064},\n",
              " {'diff': 0.024876649012999574,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.832089552238806,\n",
              "  'train_acc': 0.8072129032258064},\n",
              " {'diff': 0.01359922965816085,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.832089552238806,\n",
              "  'train_acc': 0.8184903225806451},\n",
              " {'diff': 0.008799229658160823,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.832089552238806,\n",
              "  'train_acc': 0.8232903225806452},\n",
              " {'diff': 0.008799229658160823,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.832089552238806,\n",
              "  'train_acc': 0.8232903225806452},\n",
              " {'diff': 0.010412132883967251,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.832089552238806,\n",
              "  'train_acc': 0.8216774193548387},\n",
              " {'diff': 0.008293692826191634,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8283582089552238,\n",
              "  'train_acc': 0.8200645161290322},\n",
              " {'diff': 0.01151949927780449,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8283582089552238,\n",
              "  'train_acc': 0.8168387096774193},\n",
              " {'diff': 0.01151949927780449,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8283582089552238,\n",
              "  'train_acc': 0.8168387096774193},\n",
              " {'diff': 0.01151949927780449,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8283582089552238,\n",
              "  'train_acc': 0.8168387096774193},\n",
              " {'diff': 0.004549446316803096,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8246268656716418,\n",
              "  'train_acc': 0.8200774193548387},\n",
              " {'diff': 0.018962349542609558,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8246268656716418,\n",
              "  'train_acc': 0.8056645161290322},\n",
              " {'diff': 0.0029365430909966683,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8246268656716418,\n",
              "  'train_acc': 0.8216903225806451},\n",
              " {'diff': 0.0029494463168030505,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8246268656716418,\n",
              "  'train_acc': 0.8216774193548387},\n",
              " {'diff': 0.006149446316803142,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8246268656716418,\n",
              "  'train_acc': 0.8184774193548386},\n",
              " {'diff': 0.004005199807414539,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8168903225806452},\n",
              " {'diff': 0.002405199807414604,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8184903225806451},\n",
              " {'diff': 0.015231006259027513,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8056645161290322},\n",
              " {'diff': 0.013631006259027467,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8072645161290323},\n",
              " {'diff': 0.013631006259027467,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8072645161290323},\n",
              " {'diff': 0.013631006259027467,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8072645161290323},\n",
              " {'diff': 0.0024439094848339726,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8184516129032258},\n",
              " {'diff': 0.0024439094848339726,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8184516129032258},\n",
              " {'diff': 0.008831006259027552,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8120645161290322},\n",
              " {'diff': 0.005607703418391896,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8208955223880597,\n",
              "  'train_acc': 0.8265032258064516},\n",
              " {'diff': 0.0019125662012517974,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8152516129032258},\n",
              " {'diff': 0.006686759749638838,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8104774193548387},\n",
              " {'diff': 0.006686759749638838,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8104774193548387},\n",
              " {'diff': 0.002900337024554611,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8200645161290322},\n",
              " {'diff': 0.002900337024554611,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8200645161290322},\n",
              " {'diff': 0.002900337024554611,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 5,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8200645161290322},\n",
              " {'diff': 0.0013132402503610585,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8184774193548386},\n",
              " {'diff': 0.0013132402503610585,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8171641791044776,\n",
              "  'train_acc': 0.8184774193548386},\n",
              " {'diff': 0.002968319691863286,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8134328358208955,\n",
              "  'train_acc': 0.8104645161290323},\n",
              " {'diff': 0.001355416466056858,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8134328358208955,\n",
              "  'train_acc': 0.8120774193548387},\n",
              " {'diff': 0.011431680308136682,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8134328358208955,\n",
              "  'train_acc': 0.8248645161290322},\n",
              " {'diff': 0.005044583533943103,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8134328358208955,\n",
              "  'train_acc': 0.8184774193548386},\n",
              " {'diff': 0.007175926817525324,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8168774193548387},\n",
              " {'diff': 0.0023630235917189157,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8120645161290323},\n",
              " {'diff': 0.01040173326913818,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8201032258064516},\n",
              " {'diff': 0.010375926817525305,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8200774193548387},\n",
              " {'diff': 0.007175926817525324,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8168774193548387},\n",
              " {'diff': 0.002375926817525298,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8120774193548387},\n",
              " {'diff': 0.0040369764082811566,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8056645161290322},\n",
              " {'diff': 0.002375926817525298,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8120774193548387},\n",
              " {'diff': 0.0040369764082811566,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8097014925373134,\n",
              "  'train_acc': 0.8056645161290322},\n",
              " {'diff': 0.012481463649494429,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8184516129032258},\n",
              " {'diff': 0.009345979778526692,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.815316129032258},\n",
              " {'diff': 0.004468560423688039,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8104387096774194},\n",
              " {'diff': 0.009320173326913817,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8152903225806452},\n",
              " {'diff': 0.012494366875300922,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 4,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8184645161290323},\n",
              " {'diff': 0.0013201733269138094,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8072903225806451},\n",
              " {'diff': 0.00030563312469911175,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8056645161290322},\n",
              " {'diff': 0.0013201733269138094,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8072903225806451},\n",
              " {'diff': 0.00030563312469911175,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8056645161290322},\n",
              " {'diff': 0.0013201733269138094,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8072903225806451},\n",
              " {'diff': 0.00030563312469911175,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8056645161290322},\n",
              " {'diff': 0.006120173326913836,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8059701492537313,\n",
              "  'train_acc': 0.8120903225806452},\n",
              " {'diff': 0.017838613384689395,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8200774193548387},\n",
              " {'diff': 0.019464419836302316,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8217032258064516},\n",
              " {'diff': 0.019464419836302316,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8217032258064516},\n",
              " {'diff': 0.016212806933076473,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8184516129032258},\n",
              " {'diff': 0.014638613384689414,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8168774193548387},\n",
              " {'diff': 0.017838613384689395,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8200774193548387},\n",
              " {'diff': 0.01786441983630227,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8201032258064516},\n",
              " {'diff': 0.011438613384689433,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.8022388059701493,\n",
              "  'train_acc': 0.8136774193548387},\n",
              " {'diff': 0.00391834376504574,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7985074626865671,\n",
              "  'train_acc': 0.8024258064516129},\n",
              " {'diff': 0.016769956668271524,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7985074626865671,\n",
              "  'train_acc': 0.8152774193548387},\n",
              " {'diff': 0.007294559460760741,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7985074626865671,\n",
              "  'train_acc': 0.7912129032258064},\n",
              " {'diff': 0.029595763119884433,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7985074626865671,\n",
              "  'train_acc': 0.8281032258064516},\n",
              " {'diff': 0.01516995666827159,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7985074626865671,\n",
              "  'train_acc': 0.8136774193548387},\n",
              " {'diff': 0.020540009629272937,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7947761194029851,\n",
              "  'train_acc': 0.815316129032258},\n",
              " {'diff': 0.020540009629272937,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 2,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7947761194029851,\n",
              "  'train_acc': 0.815316129032258},\n",
              " {'diff': 0.033314203177660096,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7947761194029851,\n",
              "  'train_acc': 0.8280903225806452},\n",
              " {'diff': 0.033314203177660096,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7947761194029851,\n",
              "  'train_acc': 0.8280903225806452},\n",
              " {'diff': 0.039189792970630744,\n",
              "  'max_depth': 5,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "         0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7873134328358209,\n",
              "  'train_acc': 0.8265032258064516},\n",
              " {'diff': 0.0025263360616273323,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7873134328358209,\n",
              "  'train_acc': 0.7847870967741936},\n",
              " {'diff': 0.01991237361579201,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 3,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7873134328358209,\n",
              "  'train_acc': 0.8072258064516129},\n",
              " {'diff': 0.0073134328358208656,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7873134328358209,\n",
              "  'train_acc': 0.78},\n",
              " {'diff': 0.0073134328358208656,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7873134328358209,\n",
              "  'train_acc': 0.78},\n",
              " {'diff': 0.006549253731343296,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7798507462686567,\n",
              "  'train_acc': 0.7864},\n",
              " {'diff': 0.0007064034665382746,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7761194029850746,\n",
              "  'train_acc': 0.7768258064516129},\n",
              " {'diff': 0.0006935002407317814,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7761194029850746,\n",
              "  'train_acc': 0.7768129032258064},\n",
              " {'diff': 0.0006935002407317814,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 10,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7761194029850746,\n",
              "  'train_acc': 0.7768129032258064},\n",
              " {'diff': 0.01828059701492535,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 20,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7761194029850746,\n",
              "  'train_acc': 0.7944},\n",
              " {'diff': 0.01559903707270105,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7723880597014925,\n",
              "  'train_acc': 0.7879870967741935},\n",
              " {'diff': 0.004373230621088187,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7723880597014925,\n",
              "  'train_acc': 0.7767612903225807},\n",
              " {'diff': 0.004373230621088187,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "         0, 0, 0, 0]),\n",
              "  'test_acc': 0.7723880597014925,\n",
              "  'train_acc': 0.7767612903225807},\n",
              " {'diff': 0.01560597014925369,\n",
              "  'max_depth': 15,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7611940298507462,\n",
              "  'train_acc': 0.7767999999999999},\n",
              " {'diff': 0.033193066923447256,\n",
              "  'max_depth': 10,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 15,\n",
              "  'preds': array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.7611940298507462,\n",
              "  'train_acc': 0.7943870967741935},\n",
              " {'diff': 0.016642850264805054,\n",
              "  'max_depth': 20,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.753731343283582,\n",
              "  'train_acc': 0.7703741935483871},\n",
              " {'diff': 0.01824285026480499,\n",
              "  'max_depth': 25,\n",
              "  'min_samples_leaf': 1,\n",
              "  'n_estimators': 5,\n",
              "  'preds': array([0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "         1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "         1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "         1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "         1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         0, 0, 0, 1]),\n",
              "  'test_acc': 0.753731343283582,\n",
              "  'train_acc': 0.771974193548387}]"
            ]
          },
          "metadata": {},
          "execution_count": 1083
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43JqJwO-K8JB"
      },
      "source": [
        "**precision, recall, f1 score, accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWZ1bYKgHn1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb5dabe-4ea5-4467-af45-e948c7f74208"
      },
      "source": [
        "\n",
        "y_pred = list(sorted_testacc[0]['preds'])\n",
        "y_test = list(y_test)\n",
        "\n",
        "def tptnfpfn(y_pred, y_test):\n",
        "  tp= tn= fp= fn = 0\n",
        "\n",
        "  for i in range(len(y_pred)):\n",
        "    if (y_pred[i] == 1) and (y_test[i] == 1):\n",
        "      tp +=1\n",
        "\n",
        "    if (y_pred[i] == 0) and (y_test[i] == 0):\n",
        "      tn +=1\n",
        "\n",
        "    if (y_pred[i] == 1) and (y_test[i] == 0):\n",
        "      fp +=1\n",
        "\n",
        "    if (y_pred[i] == 0) and (y_test[i] == 1):\n",
        "      fn +=1\n",
        "\n",
        "  return tp, tn, fp, fn\n",
        "  \n",
        "def accuracy(y_pred, y_test):\n",
        "  tp, tn, fp, fn = tptnfpfn(y_pred, y_test)\n",
        "  acc = (tp + tn)/(tp+tn+fp+fn)\n",
        "  return acc\n",
        "\n",
        "def precision(y_pred, y_test):\n",
        "  tp, tn, fp, fn = tptnfpfn(y_pred, y_test)\n",
        "  prec = tp/(tp+fp)\n",
        "  return prec\n",
        "\n",
        "def recall(y_pred, y_test):\n",
        "  tp, tn, fp, fn = tptnfpfn(y_pred, y_test)\n",
        "  rec = tp/(tp+fn)\n",
        "  return rec\n",
        "  \n",
        "def f1(y_pred, y_test):\n",
        "  tp, tn, fp, fn = tptnfpfn(y_pred, y_test)\n",
        "  prec = precision(y_pred, y_test)\n",
        "  rec = recall(y_pred, y_test)\n",
        "  f1 = (2*prec*rec)/(prec + rec)\n",
        "  return f1\n",
        "\n",
        "print(\"accuracy =\", accuracy(y_pred, y_test), \"\\nprecision =\", precision(y_pred, y_test), \"\\nrecall =\", recall(y_pred, y_test), \"\\nf1 =\", f1(y_pred, y_test))"
      ],
      "execution_count": 1084,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 0.8432835820895522 \n",
            "precision = 0.8961038961038961 \n",
            "recall = 0.6699029126213593 \n",
            "f1 = 0.7666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpSDT-ZlkhRS"
      },
      "source": [
        "<b>print the test accuracy and train accuracy here</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zUFG8T7kkJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac69c18-aa97-45d8-d604-7ba34d5fe049"
      },
      "source": [
        "#write code here\n",
        "print('Test accuracy=', sorted_testacc[0]['test_acc'])\n",
        "print('Train accuracy=', sorted_testacc[0]['train_acc'])"
      ],
      "execution_count": 1085,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy= 0.8432835820895522\n",
            "Train accuracy= 0.8232903225806452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47d6Vriq81y7"
      },
      "source": [
        "#S318008"
      ],
      "execution_count": 1085,
      "outputs": []
    }
  ]
}